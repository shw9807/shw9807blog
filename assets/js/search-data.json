{
  
    
        "post0": {
            "title": "[Colab] 펭귄 몸무게 예측",
            "content": "&#54189;&#44484; &#47800;&#47924;&#44172; &#50696;&#52769; . LIBRARY . import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import matplotlib get_ipython().run_line_magic(&#39;matplotlib&#39;, &#39;inline&#39;) plt.style.use(&quot;seaborn&quot;) . DATA LOADING . !unzip -uq &quot;/content/drive/MyDrive/Colab Notebooks/펭귄몸무게/dataset.zip&quot; -d &quot;/content/drive/MyDrive/Colab Notebooks/펭귄몸무게&quot; . train = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/펭귄몸무게/train.csv&quot;) test = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/펭귄몸무게/test.csv&quot;) . train.head() . id Species Island Clutch Completion Culmen Length (mm) Culmen Depth (mm) Flipper Length (mm) Sex Delta 15 N (o/oo) Delta 13 C (o/oo) Body Mass (g) . 0 0 | Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 50.0 | 15.3 | 220 | MALE | 8.30515 | -25.19017 | 5550 | . 1 1 | Chinstrap penguin (Pygoscelis antarctica) | Dream | No | 49.5 | 19.0 | 200 | MALE | 9.63074 | -24.34684 | 3800 | . 2 2 | Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 45.1 | 14.4 | 210 | FEMALE | 8.51951 | -27.01854 | 4400 | . 3 3 | Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 44.5 | 14.7 | 214 | FEMALE | 8.20106 | -26.16524 | 4850 | . 4 4 | Gentoo penguin (Pygoscelis papua) | Biscoe | No | 49.6 | 16.0 | 225 | MALE | 8.38324 | -26.84272 | 5700 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; id : 샘플 아이디 | Species: 펭귄의 종을 나타내는 문자열 | Island : 샘플들이 수집된 Palmer Station 근처 섬 이름 | Clutch Completion : 관찰된 펭귄 둥지의 알이 2개인 경우 Full Clutch이며 Yes로 표기 | Culmen Length (mm) : 펭귄 옆모습 기준 부리의 가로 길이 | Culmen Depth (mm) : 펭귄 옆모습 기준 부리의 세로 길이 | Flipper Length (mm) : 펭귄의 팔(날개) 길이 | Sex : 펭귄의 성별 | Delta 15 N (o/oo) : 토양에 따라 변화하는 안정 동위원소 15N:14N의 비율 | Delta 13 C (o/oo) : 먹이에 따라 변화하는 안정 동위원소 13C:12C의 비율 | Body Mass (g): 펭귄의 몸무게를 나타내는 숫자 (g) | . DATA CLEANSING &amp; ANALYSIS . train.drop([&#39;id&#39;],axis=1,inplace=True) test.drop([&#39;id&#39;],axis=1,inplace=True) . train.shape,test.shape . ((114, 10), (228, 9)) . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 114 entries, 0 to 113 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 Species 114 non-null object 1 Island 114 non-null object 2 Clutch Completion 114 non-null object 3 Culmen Length (mm) 114 non-null float64 4 Culmen Depth (mm) 114 non-null float64 5 Flipper Length (mm) 114 non-null int64 6 Sex 111 non-null object 7 Delta 15 N (o/oo) 111 non-null float64 8 Delta 13 C (o/oo) 111 non-null float64 9 Body Mass (g) 114 non-null int64 dtypes: float64(4), int64(2), object(4) memory usage: 9.0+ KB . train.describe() . Culmen Length (mm) Culmen Depth (mm) Flipper Length (mm) Delta 15 N (o/oo) Delta 13 C (o/oo) Body Mass (g) . count 114.000000 | 114.000000 | 114.000000 | 111.000000 | 111.000000 | 114.000000 | . mean 44.613158 | 17.014912 | 203.052632 | 8.737634 | -25.723051 | 4327.850877 | . std 5.321829 | 1.941363 | 14.653425 | 0.567698 | 0.859786 | 781.766484 | . min 33.500000 | 13.200000 | 174.000000 | 7.632200 | -27.018540 | 2700.000000 | . 25% 40.325000 | 15.225000 | 190.000000 | 8.272585 | -26.434025 | 3675.000000 | . 50% 45.200000 | 17.250000 | 199.000000 | 8.632590 | -25.955410 | 4250.000000 | . 75% 49.075000 | 18.600000 | 216.000000 | 9.264635 | -25.005945 | 4850.000000 | . max 55.100000 | 21.100000 | 231.000000 | 10.025440 | -24.102550 | 6300.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; target = train[&#39;Body Mass (g)&#39;] object_columns = [&#39;Species&#39;,&#39;Island&#39;,&#39;Clutch Completion&#39;,&#39;Sex&#39;] numerical_columns= [&#39;Culmen Depth (mm)&#39;,&#39;Culmen Length (mm)&#39;,&#39;Flipper Length (mm)&#39;,&#39;Delta 15 N (o/oo)&#39;,&#39;Delta 13 C (o/oo)&#39;] . Object Columns . for _ in object_columns: print(_) print(train[_].value_counts()) plt.figure(figsize=(15,5)) sns.countplot(x=train[_],palette=&#39;Set3&#39;) plt.show() . Species Gentoo penguin (Pygoscelis papua) 48 Adelie Penguin (Pygoscelis adeliae) 41 Chinstrap penguin (Pygoscelis antarctica) 25 Name: Species, dtype: int64 . Island Biscoe 57 Dream 44 Torgersen 13 Name: Island, dtype: int64 . Clutch Completion Yes 102 No 12 Name: Clutch Completion, dtype: int64 . Sex MALE 56 FEMALE 55 Name: Sex, dtype: int64 . Numerical Columns . plt.style.use(&#39;fivethirtyeight&#39;) for _ in numerical_columns: print(_) f,ax=plt.subplots(1,2,figsize=(16,4)) plt.figure(figsize=(15,5)) sns.histplot(x=train[_],ax=ax[0],kde=True) sns.boxplot(x=train[_],ax=ax[1],color=&#39;white&#39;) plt.show() . Culmen Depth (mm) . &lt;Figure size 1080x360 with 0 Axes&gt; . Culmen Length (mm) . &lt;Figure size 1080x360 with 0 Axes&gt; . Flipper Length (mm) . &lt;Figure size 1080x360 with 0 Axes&gt; . Delta 15 N (o/oo) . &lt;Figure size 1080x360 with 0 Axes&gt; . Delta 13 C (o/oo) . &lt;Figure size 1080x360 with 0 Axes&gt; . f,ax= plt.subplots(2,1,figsize=(9,8)) sns.swarmplot(data=train, x=&#39;Species&#39;,y=&#39;Body Mass (g)&#39;,ax=ax[0]); ax[0].set_title(&quot;Body Mass(g) by Species&quot;) sns.swarmplot(data=train, x=&#39;Species&#39;,y=&#39;Body Mass (g)&#39;,hue=&#39;Sex&#39;,ax=ax[1]); ax[1].set_title(&quot;Body Mass(g) by [Species, Sex]&quot;) plt.tight_layout() #Show clearly. . f,ax=plt.subplots(1,3,figsize=(15,5)) sns.regplot(data=train, x=&#39;Culmen Length (mm)&#39;,y=&#39;Body Mass (g)&#39;,ax=ax[0],color=&#39;red&#39;) sns.regplot(data=train, x=&#39;Culmen Depth (mm)&#39;,y=&#39;Body Mass (g)&#39;,ax=ax[1],color=&#39;blue&#39;) sns.regplot(data=train, x=&#39;Flipper Length (mm)&#39;,y=&#39;Body Mass (g)&#39;,ax=ax[2],color=&#39;green&#39;) plt.tight_layout() . Observation . [Culmen Length (mm), Culmen Depth (mm), Flipper Length (mm)] 컬럼들이 전반적으로 Body Mass (g)과 상관관계를 가진다고 할 수 있습니다. . plt.style.use(&#39;seaborn&#39;) g= sns.pairplot(train,hue=&#39;Species&#39;) g.map_lower(sns.regplot); . plt.figure(figsize=(16,8)) sns.heatmap(train.corr(),annot=True,vmin=-1, vmax=1); . Processing . &#44208;&#52769;&#44050; &#52376;&#47532; . train.isnull().sum() . Species 0 Island 0 Clutch Completion 0 Culmen Length (mm) 0 Culmen Depth (mm) 0 Flipper Length (mm) 0 Sex 3 Delta 15 N (o/oo) 3 Delta 13 C (o/oo) 3 Body Mass (g) 0 dtype: int64 . Delta 피쳐들은 평균으로 채워볼 수 있습니다.. 또한, Sex 피쳐를 다루기 위해서 drop이나 mode로 채울 수 있습니다. 그러나 데이터가 적기 때문에 &#39;합리적으로&#39; 결측값을 채워봅시다. . train.corr()[&#39;Body Mass (g)&#39;] . Culmen Length (mm) 0.572063 Culmen Depth (mm) -0.490643 Flipper Length (mm) 0.864814 Delta 15 N (o/oo) -0.548678 Delta 13 C (o/oo) -0.468425 Body Mass (g) 1.000000 Name: Body Mass (g), dtype: float64 . sns.scatterplot(data=train, x=&#39;Flipper Length (mm)&#39;, y= &#39;Body Mass (g)&#39;, hue=&#39;Sex&#39;); . Flipper Length (mm) &amp; Body Mass (g)의 상관관계가 높은 것으로 보입니다.또한 성별로 나누었을 때도 구분이 됩니다. . train.groupby([&#39;Species&#39;,&#39;Sex&#39;])[&#39;Flipper Length (mm)&#39;].mean().reset_index() . Species Sex Flipper Length (mm) . 0 Adelie Penguin (Pygoscelis adeliae) | FEMALE | 187.166667 | . 1 Adelie Penguin (Pygoscelis adeliae) | MALE | 191.619048 | . 2 Chinstrap penguin (Pygoscelis antarctica) | FEMALE | 192.642857 | . 3 Chinstrap penguin (Pygoscelis antarctica) | MALE | 200.454545 | . 4 Gentoo penguin (Pygoscelis papua) | FEMALE | 213.217391 | . 5 Gentoo penguin (Pygoscelis papua) | MALE | 223.000000 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train[train[&#39;Sex&#39;].isnull()] . Species Island Clutch Completion Culmen Length (mm) Culmen Depth (mm) Flipper Length (mm) Sex Delta 15 N (o/oo) Delta 13 C (o/oo) Body Mass (g) . 6 Adelie Penguin (Pygoscelis adeliae) | Torgersen | Yes | 42.0 | 20.2 | 190 | NaN | 9.13362 | -25.09368 | 4250 | . 8 Adelie Penguin (Pygoscelis adeliae) | Torgersen | Yes | 34.1 | 18.1 | 193 | NaN | NaN | NaN | 3475 | . 70 Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 46.2 | 14.4 | 214 | NaN | 8.24253 | -26.81540 | 4650 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; 예를 들어, 6번의 인덱스를 보면. Adelie Penguin (Pygoscelis adeliae 종의 Flipper Length (mm)는 190입니다. 위의 표와 함께 유추하면, 성별은 &#39;MALE&#39;로 유추해볼 수 있습니다. . (결측값이 많을 때에는 좋은 방법이 아닐 겁니다.) . test.groupby([&#39;Species&#39;,&#39;Sex&#39;])[&#39;Flipper Length (mm)&#39;].mean().reset_index() . Species Sex Flipper Length (mm) . 0 Adelie Penguin (Pygoscelis adeliae) | FEMALE | 188.000000 | . 1 Adelie Penguin (Pygoscelis adeliae) | MALE | 192.730769 | . 2 Chinstrap penguin (Pygoscelis antarctica) | FEMALE | 191.100000 | . 3 Chinstrap penguin (Pygoscelis antarctica) | MALE | 199.652174 | . 4 Gentoo penguin (Pygoscelis papua) | FEMALE | 212.371429 | . 5 Gentoo penguin (Pygoscelis papua) | MALE | 220.594595 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; test[test[&#39;Sex&#39;].isnull()] . Species Island Clutch Completion Culmen Length (mm) Culmen Depth (mm) Flipper Length (mm) Sex Delta 15 N (o/oo) Delta 13 C (o/oo) . 46 Adelie Penguin (Pygoscelis adeliae) | Torgersen | Yes | 37.8 | 17.1 | 186.0 | NaN | 8.63243 | -25.21315 | . 81 Adelie Penguin (Pygoscelis adeliae) | Dream | Yes | 37.5 | 18.9 | 179.0 | NaN | NaN | NaN | . 98 Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 47.3 | 13.8 | 216.0 | NaN | 8.25818 | -26.23886 | . 152 Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 44.5 | 15.7 | 217.0 | NaN | 8.04111 | -26.18444 | . 205 Adelie Penguin (Pygoscelis adeliae) | Torgersen | Yes | 37.8 | 17.3 | 180.0 | NaN | NaN | NaN | . 209 Gentoo penguin (Pygoscelis papua) | Biscoe | Yes | 44.5 | 14.3 | 216.0 | NaN | 7.96621 | -25.69327 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train.fillna(train.mean(), inplace = True) test.fillna(train.mean(), inplace = True) train.loc[6,&#39;Sex&#39;]=&#39;MALE&#39; train.loc[8,&#39;Sex&#39;]=&#39;MALE&#39; train.loc[70,&#39;Sex&#39;]=&#39;FEMALE&#39; #test Dataset test.loc[46,&#39;Sex&#39;]=&#39;FEMALE&#39; test.loc[81,&#39;Sex&#39;]=&#39;FEMALE&#39; test.loc[98,&#39;Sex&#39;]=&#39;MALE&#39; test.loc[152,&#39;Sex&#39;]=&#39;MALE&#39; test.loc[205,&#39;Sex&#39;]=&#39;FEMALE&#39; test.loc[209,&#39;Sex&#39;]=&#39;FEMALE&#39; . Encoding . train = pd.get_dummies(train) test = pd.get_dummies(test) . Scale . from sklearn.preprocessing import StandardScaler ss=StandardScaler() train_scaler=ss.fit_transform(train[numerical_columns]) train[numerical_columns] = pd.DataFrame(data=train_scaler, columns=numerical_columns) test_scaler= ss.transform(test[numerical_columns]) test[numerical_columns] = pd.DataFrame(data=test_scaler, columns=numerical_columns) . standardscaler를 사용해 수치형 칼럼들의 값을 평균0, 분산1로 조정해주었다. . MODELING . from sklearn.model_selection import train_test_split from sklearn.linear_model import Ridge,BayesianRidge . X=train.drop([&#39;Body Mass (g)&#39;],axis=1) y= train[&#39;Body Mass (g)&#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) . import matplotlib.pyplot as plt # alpha 값을 바꿀 때마다 score() 메서드의 결과를 저장할 리스트 train_score = [] test_score = [] . from sklearn.linear_model import Ridge from sklearn.model_selection import cross_val_score alphas = [0,0.01,0.1,1,10,100] for alpha in alphas: ridge = Ridge(alpha=alpha) ridge.fit(X_train,y_train) train_score.append(ridge.score(X_train,y_train)) test_score.append(ridge.score(X_test, y_test)) neg_mse_scores = cross_val_score(ridge, X, y, scoring = &#39;neg_mean_squared_error&#39;, cv = 5) avg_rmse = np.mean(np.sqrt(-neg_mse_scores)) print(&#39;alpha 값 &#39;, alpha, &#39;일때 평균 rmse :&#39;, np.round(avg_rmse,4)) . alpha 값 0 일때 평균 rmse : 341.8353 alpha 값 0.01 일때 평균 rmse : 335.4318 alpha 값 0.1 일때 평균 rmse : 334.5428 alpha 값 1 일때 평균 rmse : 330.299 alpha 값 10 일때 평균 rmse : 328.4763 alpha 값 100 일때 평균 rmse : 404.5087 . plt.plot(np.log10(alphas), train_score) plt.plot(np.log10(alphas), test_score) plt.xlabel(&#39;alpha&#39;) plt.ylabel(&#39;R^2&#39;) plt.show() . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log10 &#34;&#34;&#34;Entry point for launching an IPython kernel. /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log10 . ridge = Ridge(alpha=0.01) ridge.fit(X_train,y_train) pred= ridge.predict(X_test) print(ridge.score(X_test,y_test)) . 0.8290727649695923 . ridge = Ridge(alpha=1) ridge.fit(X_train,y_train) pred= ridge.predict(X_test) print(ridge.score(X_test,y_test)) . 0.8255628368059518 . EVALUATION . import numpy as np def RMSE(true, pred): score = np.sqrt(np.mean(np.square(true-pred))) return score RMSE(y_test,pred) . 311.60898494936004 . import numpy as np def RMSE(true, pred): score = np.sqrt(np.mean(np.square(true-pred))) return score RMSE(y_test,pred) . 314.79211507025906 .",
            "url": "https://shw9807.github.io/shw9807blog/%EB%8D%B0%EC%9D%B4%EC%BD%98/2022/02/17/%ED%8E%AD%EA%B7%84%EB%AA%B8%EB%AC%B4%EA%B2%8C%EC%98%88%EC%B8%A1.html",
            "relUrl": "/%EB%8D%B0%EC%9D%B4%EC%BD%98/2022/02/17/%ED%8E%AD%EA%B7%84%EB%AA%B8%EB%AC%B4%EA%B2%8C%EC%98%88%EC%B8%A1.html",
            "date": " • Feb 17, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "[Colab] 타이타닉 데이터 분석",
            "content": "&#53440;&#51060;&#53440;&#45769; &#45936;&#51060;&#53552; &#48516;&#49437; . !sudo apt-get install -y fonts-nanum !sudo fc-cache -fv !rm ~/.cache/matplotlib -rf . Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: fonts-nanum 0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded. Need to get 9,604 kB of archives. After this operation, 29.5 MB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB] Fetched 9,604 kB in 2s (6,127 kB/s) debconf: unable to initialize frontend: Dialog debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 1.) debconf: falling back to frontend: Readline debconf: unable to initialize frontend: Readline debconf: (This frontend requires a controlling tty.) debconf: falling back to frontend: Teletype dpkg-preconfigure: unable to re-open stdin: Selecting previously unselected package fonts-nanum. (Reading database ... 155229 files and directories currently installed.) Preparing to unpack .../fonts-nanum_20170925-1_all.deb ... Unpacking fonts-nanum (20170925-1) ... Setting up fonts-nanum (20170925-1) ... Processing triggers for fontconfig (2.12.6-0ubuntu2) ... /usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs /usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs /usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs /usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs /usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs /usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs /root/.local/share/fonts: skipping, no such directory /root/.fonts: skipping, no such directory /var/cache/fontconfig: cleaning cache directory /root/.cache/fontconfig: not cleaning non-existent cache directory /root/.fontconfig: not cleaning non-existent cache directory fc-cache: succeeded . import warnings; warnings.filterwarnings(&#39;ignore&#39;) import matplotlib.pyplot as plt import matplotlib as mpl import matplotlib.font_manager as fm import numpy as npn import pandas as pd import seaborn as sns plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) . !unzip -uq &quot;/content/drive/MyDrive/Colab Notebooks/타이타닉/타이타닉.zip&quot; -d &quot;/content/drive/MyDrive/Colab Notebooks/타이타닉&quot; . test = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/타이타닉/test.csv&quot;) train = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/타이타닉/train.csv&quot;) submission = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/타이타닉/submission.csv&quot;) . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; PassengerID : 탑승객 고유 아이디 Survival : 탑승객 생존 유무 (0: 사망, 1: 생존) Pclass : 등실의 등급 Name : 이름 Sex : 성별 Age : 나이 Sibsp : 함께 탐승한 형제자매, 아내, 남편의 수 Parch : 함께 탐승한 부모, 자식의 수 Ticket :티켓 번호 Fare : 티켓의 요금 Cabin : 객실번호 Embarked : 배에 탑승한 항구 이름 ( C = Cherbourn, Q = Queenstown, S = Southampton) . 일단 객실 등급과 성별, 나이, 티켓요금, 탑승한 항구 이름 정도가 영향이 있지 않았을까 싶다. . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB . 객실번호와 나이를 제외한 변수들은 결측치를 가지지 않음을 확인할 수 있다. . train.describe() . PassengerId Survived Pclass Age SibSp Parch Fare . count 891.000000 | 891.000000 | 891.000000 | 714.000000 | 891.000000 | 891.000000 | 891.000000 | . mean 446.000000 | 0.383838 | 2.308642 | 29.699118 | 0.523008 | 0.381594 | 32.204208 | . std 257.353842 | 0.486592 | 0.836071 | 14.526497 | 1.102743 | 0.806057 | 49.693429 | . min 1.000000 | 0.000000 | 1.000000 | 0.420000 | 0.000000 | 0.000000 | 0.000000 | . 25% 223.500000 | 0.000000 | 2.000000 | 20.125000 | 0.000000 | 0.000000 | 7.910400 | . 50% 446.000000 | 0.000000 | 3.000000 | 28.000000 | 0.000000 | 0.000000 | 14.454200 | . 75% 668.500000 | 1.000000 | 3.000000 | 38.000000 | 1.000000 | 0.000000 | 31.000000 | . max 891.000000 | 1.000000 | 3.000000 | 80.000000 | 8.000000 | 6.000000 | 512.329200 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train.loc[train[&#39;Age&#39;].isna()] . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 5 6 | 0 | 3 | Moran, Mr. James | male | NaN | 0 | 0 | 330877 | 8.4583 | NaN | Q | . 17 18 | 1 | 2 | Williams, Mr. Charles Eugene | male | NaN | 0 | 0 | 244373 | 13.0000 | NaN | S | . 19 20 | 1 | 3 | Masselmani, Mrs. Fatima | female | NaN | 0 | 0 | 2649 | 7.2250 | NaN | C | . 26 27 | 0 | 3 | Emir, Mr. Farred Chehab | male | NaN | 0 | 0 | 2631 | 7.2250 | NaN | C | . 28 29 | 1 | 3 | O&#39;Dwyer, Miss. Ellen &quot;Nellie&quot; | female | NaN | 0 | 0 | 330959 | 7.8792 | NaN | Q | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 859 860 | 0 | 3 | Razi, Mr. Raihed | male | NaN | 0 | 0 | 2629 | 7.2292 | NaN | C | . 863 864 | 0 | 3 | Sage, Miss. Dorothy Edith &quot;Dolly&quot; | female | NaN | 8 | 2 | CA. 2343 | 69.5500 | NaN | S | . 868 869 | 0 | 3 | van Melkebeke, Mr. Philemon | male | NaN | 0 | 0 | 345777 | 9.5000 | NaN | S | . 878 879 | 0 | 3 | Laleff, Mr. Kristo | male | NaN | 0 | 0 | 349217 | 7.8958 | NaN | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.4500 | NaN | S | . 177 rows × 12 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train.loc[(train[&#39;Age&#39;].isna()) &amp; (train[&#39;SibSp&#39;] == 0 ) &amp; (train[&#39;Parch&#39;] == 0)] . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 5 6 | 0 | 3 | Moran, Mr. James | male | NaN | 0 | 0 | 330877 | 8.4583 | NaN | Q | . 17 18 | 1 | 2 | Williams, Mr. Charles Eugene | male | NaN | 0 | 0 | 244373 | 13.0000 | NaN | S | . 19 20 | 1 | 3 | Masselmani, Mrs. Fatima | female | NaN | 0 | 0 | 2649 | 7.2250 | NaN | C | . 26 27 | 0 | 3 | Emir, Mr. Farred Chehab | male | NaN | 0 | 0 | 2631 | 7.2250 | NaN | C | . 28 29 | 1 | 3 | O&#39;Dwyer, Miss. Ellen &quot;Nellie&quot; | female | NaN | 0 | 0 | 330959 | 7.8792 | NaN | Q | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 837 838 | 0 | 3 | Sirota, Mr. Maurice | male | NaN | 0 | 0 | 392092 | 8.0500 | NaN | S | . 839 840 | 1 | 1 | Marechal, Mr. Pierre | male | NaN | 0 | 0 | 11774 | 29.7000 | C47 | C | . 859 860 | 0 | 3 | Razi, Mr. Raihed | male | NaN | 0 | 0 | 2629 | 7.2292 | NaN | C | . 868 869 | 0 | 3 | van Melkebeke, Mr. Philemon | male | NaN | 0 | 0 | 345777 | 9.5000 | NaN | S | . 878 879 | 0 | 3 | Laleff, Mr. Kristo | male | NaN | 0 | 0 | 349217 | 7.8958 | NaN | S | . 133 rows × 12 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; train.groupby(&#39;Pclass&#39;)[&#39;Age&#39;].mean() . Pclass 1 38.233441 2 29.877630 3 25.140620 Name: Age, dtype: float64 . plt.figure(figsize=[10,10]) sns.scatterplot(data=train, x=&#39;Pclass&#39;, y = &#39;Age&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f7044f33410&gt; . findfont: Font family [&#39;NanumBarunGothic&#39;] not found. Falling back to DejaVu Sans. . &#44208;&#52769;&#52824; &#52376;&#47532; . 객실등급에 따라서 나이의 평균에 차이가 있는 것으로 보인다. 아무래도 비싼 객실일수록 평균 나이대가 높아지는 경향이 있는 것으로 보인다. 나이의 결측치들을 객실등급별로 평균값으로 채워주면 될 것 같다. . meanage = train.groupby(&#39;Pclass&#39;)[&#39;Age&#39;].mean() . train.loc[(train[&#39;Age&#39;].isna()) &amp; (train[&#39;Pclass&#39;] == 1), &#39;Age&#39;] = meanage[1] train.loc[(train[&#39;Age&#39;].isna()) &amp; (train[&#39;Pclass&#39;] == 2),&#39;Age&#39;] = meanage[2] train.loc[(train[&#39;Age&#39;].isna()) &amp; (train[&#39;Pclass&#39;] == 3),&#39;Age&#39;] = meanage[3] . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 891 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB . Cabin은 결측치도 많고 별로 의미가 없을까 싶다. 변수 자체를 없애는 것이 나아보인다. Embarked는 결측치가 몇 개 존재하지 않는다. 가장 자주 나온 변수로 채워주어도 괜찮을 것으로 보인다. . train[&#39;Embarked&#39;].value_counts() . S 644 C 168 Q 77 Name: Embarked, dtype: int64 . S 가 가장 많이 나타나므로 결측치는 S로 채워주도록 하자. . train[&#39;Embarked&#39;].fillna(value = &#39;S&#39;, inplace = True) . train[&#39;Embarked&#39;].isna().sum() . 0 . 테스트 데이터에도 똑같이 적용해준다. . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 418 entries, 0 to 417 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 418 non-null int64 1 Pclass 418 non-null int64 2 Name 418 non-null object 3 Sex 418 non-null object 4 Age 332 non-null float64 5 SibSp 418 non-null int64 6 Parch 418 non-null int64 7 Ticket 418 non-null object 8 Fare 417 non-null float64 9 Cabin 91 non-null object 10 Embarked 418 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 36.0+ KB . test.loc[(test[&#39;Age&#39;].isna()) &amp; (test[&#39;Pclass&#39;] == 1), &#39;Age&#39;] = meanage[1] test.loc[(test[&#39;Age&#39;].isna()) &amp; (test[&#39;Pclass&#39;] == 2),&#39;Age&#39;] = meanage[2] test.loc[(test[&#39;Age&#39;].isna()) &amp; (test[&#39;Pclass&#39;] == 3),&#39;Age&#39;] = meanage[3] . test.isna().sum() . PassengerId 0 Pclass 0 Name 0 Sex 0 Age 0 SibSp 0 Parch 0 Ticket 0 Fare 1 Cabin 327 Embarked 0 dtype: int64 . 성별이 &#39;male&#39;과 &#39;female&#39;로 설정되어 있는데 0과 1의 값을 가지는 변수로 변환해주자 . train[&#39;Sex&#39;] = train[&#39;Sex&#39;].map({&#39;male&#39;:0, &#39;female&#39;:1}) . test[&#39;Sex&#39;] = test[&#39;Sex&#39;].map({&#39;male&#39;:0, &#39;female&#39;:1}) . &#45936;&#51060;&#53552; &#49884;&#44033;&#54868; . plt.figure(figsize=[10,10]) sns.barplot(data=train, x=&#39;Pclass&#39;, y = &#39;Survived&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f702f48df90&gt; . 확실히 객실의 등급이 높을수록 생존할 확률이 높아지는것을 확인할 수 있다. . plt.figure(figsize=[10,10]) sns.barplot(data=train, x=&#39;Sex&#39;, y = &#39;Survived&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f70268cff50&gt; . 여자가 남자에 비해서 압도적으로 생존확률이 높은 것을 확인할 수 있다. . plt.figure(figsize=[10,10]) sns.barplot(data=train, x=&#39;Embarked&#39;, y = &#39;Survived&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f70260125d0&gt; . sns.lmplot(data=train, x=&#39;Age&#39;, y = &#39;Survived&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f702f3c2e10&gt; . 나이별로 생존률에 차이가 있는지를 어떻게 확인해보려고 했는데 잘 안된다.... 큰차이는 없다..? 나이가 많아질수록 생존확률이 낮아진다? 정도로 볼 수 있을 것 같다. . %matplotlib inline train.hist(bins = 50, figsize = (20,15)) plt.show() . &#48320;&#49688; &#49440;&#53469; &#48143; &#47784;&#45944; &#44396;&#52629; . sklearn.linear_model.LogisticRegression() . 로지스틱 함수를 통해 0과 1사이의 값을 산출하여, 탑승객의 생존 여부를 파악해봅시다. . X_train = train[[&#39;Pclass&#39;, &#39;Age&#39;]] y_train = train[&#39;Survived&#39;] X_test = test[[&#39;Pclass&#39;, &#39;Age&#39;]] . from sklearn.linear_model import LogisticRegression model = LogisticRegression() . model.fit(X_train, y_train) . LogisticRegression() . y_pred = model.predict(X_test) . submission[&#39;Survived&#39;] = y_pred . submission.to_csv(&#39;lr_model_Pclass_Age.csv&#39;, index = False) . sklearn.tree.DecisionTreeClassifier() . 특징변수들로부터 타깃변수를 맞추기 위해 경우를 쪼개나가는 알고리즘입니다. (예) 과일이 사과, 딸기, 포도 중 무엇인지 맞추려합니다 . 주어진 특징은 과일 1개의 가로최대길이, 세로최대길이, 과일의색상이라고 합시다 | 사과를 맞추기 위해서 10 ~ 13cm의 가로, 세로 최대길이와 빨간색의 과일을 탐색하게 되겠죠 | 위의 &#39;길이가 10 ~ 13cm인가? 아닌가?&#39;, &#39;색깔이 빨간색인가? 아닌가?&#39;의 기준이 경우를 쪼개나가는 기준이 됩니다. | . from sklearn.tree import DecisionTreeClassifier dt_model = DecisionTreeClassifier() . dt_model.fit(X_train, y_train) . DecisionTreeClassifier() . submission[&#39;Survived&#39;] = dt_model.predict(X_test) . submission.to_csv(&#39;dt_model.csv&#39;, index = False) . &#47784;&#45944; &#54617;&#49845; &#48143; &#44160;&#51613; . submission[&#39;Survived&#39;] = model.predict_proba(X_test)[:,1] . submission.to_csv(&#39;lr_proba.csv&#39;, index = False) . submission[&#39;Survived&#39;] = dt_model.predict_proba(X_test)[:,1] . submission.to_csv(&#39;dt_proba.csv&#39;, index = False) . DecisionTreeClassifier() . DecisionTreeClassifier() . dt_model_new = DecisionTreeClassifier(min_samples_split=10) . dt_model_new.fit(X_train, y_train) . DecisionTreeClassifier(min_samples_split=10) . submission[&#39;Survived&#39;] = dt_model_new.predict_proba(X_test)[:, 1] . submission.to_csv(&#39;dt_min_samples_10_proba.csv&#39;, index = False) . train . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | 0 | 22.00000 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | 1 | 38.00000 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | 1 | 26.00000 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | 1 | 35.00000 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | 0 | 35.00000 | 0 | 0 | 373450 | 8.0500 | NaN | S | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 887 | 0 | 2 | Montvila, Rev. Juozas | 0 | 27.00000 | 0 | 0 | 211536 | 13.0000 | NaN | S | . 887 888 | 1 | 1 | Graham, Miss. Margaret Edith | 1 | 19.00000 | 0 | 0 | 112053 | 30.0000 | B42 | S | . 888 889 | 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | 1 | 25.14062 | 1 | 2 | W./C. 6607 | 23.4500 | NaN | S | . 889 890 | 1 | 1 | Behr, Mr. Karl Howell | 0 | 26.00000 | 0 | 0 | 111369 | 30.0000 | C148 | C | . 890 891 | 0 | 3 | Dooley, Mr. Patrick | 0 | 32.00000 | 0 | 0 | 370376 | 7.7500 | NaN | Q | . 891 rows × 12 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; . from sklearn.metrics import confusion_matrix, classification_report from sklearn.metrics import precision_score from sklearn.metrics import recall_score from sklearn.metrics import accuracy_score from sklearn.metrics import roc_auc_score . X_train = train[[&#39;Pclass&#39;, &#39;Age&#39;]] y_train = train[&#39;Survived&#39;] X_test = test[[&#39;Pclass&#39;, &#39;Age&#39;]] . model = LogisticRegression() model.fit(X_train, y_train) y_pred = model.predict(X_train) . y_true = y_train.values . cf_matrix = confusion_matrix(y_true, y_pred) . cf_matrix . array([[466, 83], [183, 159]]) . accuracy_score(y_true, y_pred) . 0.7014590347923682 . (cf_matrix[0,0] + cf_matrix[1,1]) / 891 . 0.7014590347923682 . precision_score(y_true, y_pred) . 0.6570247933884298 . (cf_matrix[1,1]) / (83 + 160) . 0.654320987654321 . recall_score(y_true, y_pred) . 0.4649122807017544 . (cf_matrix[1,1]) / (182 + 160) . 0.4649122807017544 . print(classification_report(y_true, y_pred)) . precision recall f1-score support 0 0.72 0.85 0.78 549 1 0.66 0.46 0.54 342 accuracy 0.70 891 macro avg 0.69 0.66 0.66 891 weighted avg 0.69 0.70 0.69 891 . 데이콘 채점 기준은 auc 라는 지표를 사용합니다. | auc값을 측정하기 위해서는, 예측을 확률값으로 해주어야 합니다. | 그 중에서 1에 속할 확률을 선택해주어야 합니다. | . roc_auc_score(y_true, y_pred) . 0.6568641549228261 . &#44208;&#44284; &#48143; &#44208;&#50616; . import pandas as pd from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import KFold from sklearn.metrics import roc_auc_score . model_10 = DecisionTreeClassifier(min_samples_split=10) model_20 = DecisionTreeClassifier(min_samples_split=20) model_30 = DecisionTreeClassifier(min_samples_split=30) . kfold = KFold(n_splits=5, shuffle=True, random_state=10) . score_10 = [] for trn_idx, val_idx in kfold.split(X_train): X_trn, y_trn = X_train.iloc[trn_idx, :], y_train.iloc[trn_idx] X_val, y_val = X_train.iloc[val_idx, :], y_train.iloc[val_idx] model_10.fit(X_trn, y_trn) y_pred = model_10.predict_proba(X_val)[:, 1] print(&#39;예측 완료&#39;) score_10.append(roc_auc_score(y_val.values, y_pred)) . 예측 완료 예측 완료 예측 완료 예측 완료 예측 완료 . score_10 . [0.666528811690102, 0.6923701298701299, 0.6616221174004193, 0.58994708994709, 0.7008647798742138] . score_20 = [] for trn_idx, val_idx in kfold.split(X_train): X_trn, y_trn = X_train.iloc[trn_idx, :], y_train.iloc[trn_idx] X_val, y_val = X_train.iloc[val_idx, :], y_train.iloc[val_idx] model_20.fit(X_trn, y_trn) y_pred = model_20.predict_proba(X_val)[:, 1] print(&#39;예측 완료&#39;) score_20.append(roc_auc_score(y_val.values, y_pred)) . 예측 완료 예측 완료 예측 완료 예측 완료 예측 완료 . score_20 . [0.6767300799558864, 0.696766774891775, 0.6660770440251572, 0.608531746031746, 0.7118055555555556] . score_30 = [] for trn_idx, val_idx in kfold.split(X_train): X_trn, y_trn = X_train.iloc[trn_idx, :], y_train.iloc[trn_idx] X_val, y_val = X_train.iloc[val_idx, :], y_train.iloc[val_idx] model_30.fit(X_trn, y_trn) y_pred = model_30.predict_proba(X_val)[:, 1] print(&#39;예측 완료&#39;) score_30.append(roc_auc_score(y_val.values, y_pred)) . 예측 완료 예측 완료 예측 완료 예측 완료 예측 완료 . score_30 . [0.6944444444444444, 0.7076569264069265, 0.6582154088050315, 0.6217592592592592, 0.7237945492662475] . import numpy as np . np.mean(score_10), np.mean(score_20), np.mean(score_30) . (0.662266585756391, 0.671982240092024, 0.6811741176363818) . 추가로 성별까지 변수에 추가하여 점수를 확인해보자. . X_train = train[[&#39;Pclass&#39;, &#39;Age&#39;, &#39;Sex&#39;]] y_train = train[&#39;Survived&#39;] X_test = test[[&#39;Pclass&#39;, &#39;Age&#39;, &#39;Sex&#39;]] . score_10 = [] for trn_idx, val_idx in kfold.split(X_train): X_trn, y_trn = X_train.iloc[trn_idx, :], y_train.iloc[trn_idx] X_val, y_val = X_train.iloc[val_idx, :], y_train.iloc[val_idx] model_10.fit(X_trn, y_trn) y_pred = model_10.predict_proba(X_val)[:, 1] print(&#39;예측 완료&#39;) score_10.append(roc_auc_score(y_val.values, y_pred)) . 예측 완료 예측 완료 예측 완료 예측 완료 예측 완료 . score_20 = [] for trn_idx, val_idx in kfold.split(X_train): X_trn, y_trn = X_train.iloc[trn_idx, :], y_train.iloc[trn_idx] X_val, y_val = X_train.iloc[val_idx, :], y_train.iloc[val_idx] model_20.fit(X_trn, y_trn) y_pred = model_20.predict_proba(X_val)[:, 1] print(&#39;예측 완료&#39;) score_20.append(roc_auc_score(y_val.values, y_pred)) . 예측 완료 예측 완료 예측 완료 예측 완료 예측 완료 . score_30 = [] for trn_idx, val_idx in kfold.split(X_train): X_trn, y_trn = X_train.iloc[trn_idx, :], y_train.iloc[trn_idx] X_val, y_val = X_train.iloc[val_idx, :], y_train.iloc[val_idx] model_30.fit(X_trn, y_trn) y_pred = model_30.predict_proba(X_val)[:, 1] print(&#39;예측 완료&#39;) score_30.append(roc_auc_score(y_val.values, y_pred)) . 예측 완료 예측 완료 예측 완료 예측 완료 예측 완료 . np.mean(score_10), np.mean(score_20), np.mean(score_30) . (0.8173547973745784, 0.8224093714579868, 0.8311338310733472) . from sklearn import tree . plt.figure( figsize=(20,15) ) tree.plot_tree(model_30, impurity=True, filled=True, rounded=True) . [Text(0.5275735294117647, 0.9615384615384616, &#39;X[2] &lt;= 0.5 ngini = 0.471 nsamples = 713 nvalue = [443, 270]&#39;), Text(0.2610294117647059, 0.8846153846153846, &#39;X[0] &lt;= 1.5 ngini = 0.31 nsamples = 465 nvalue = [376, 89]&#39;), Text(0.11764705882352941, 0.8076923076923077, &#39;X[1] &lt;= 36.5 ngini = 0.468 nsamples = 102 nvalue = [64, 38]&#39;), Text(0.058823529411764705, 0.7307692307692307, &#39;X[1] &lt;= 33.5 ngini = 0.484 nsamples = 34 nvalue = [14, 20]&#39;), Text(0.029411764705882353, 0.6538461538461539, &#39;gini = 0.499 nsamples = 25 nvalue = [13, 12]&#39;), Text(0.08823529411764706, 0.6538461538461539, &#39;gini = 0.198 nsamples = 9 nvalue = [1, 8]&#39;), Text(0.17647058823529413, 0.7307692307692307, &#39;X[1] &lt;= 60.5 ngini = 0.389 nsamples = 68 nvalue = [50, 18]&#39;), Text(0.14705882352941177, 0.6538461538461539, &#39;X[1] &lt;= 47.5 ngini = 0.42 nsamples = 60 nvalue = [42, 18]&#39;), Text(0.11764705882352941, 0.5769230769230769, &#39;X[1] &lt;= 45.25 ngini = 0.381 nsamples = 39 nvalue = [29, 10]&#39;), Text(0.08823529411764706, 0.5, &#39;X[1] &lt;= 41.0 ngini = 0.415 nsamples = 34 nvalue = [24, 10]&#39;), Text(0.058823529411764705, 0.4230769230769231, &#39;gini = 0.384 nsamples = 27 nvalue = [20, 7]&#39;), Text(0.11764705882352941, 0.4230769230769231, &#39;gini = 0.49 nsamples = 7 nvalue = [4, 3]&#39;), Text(0.14705882352941177, 0.5, &#39;gini = 0.0 nsamples = 5 nvalue = [5, 0]&#39;), Text(0.17647058823529413, 0.5769230769230769, &#39;gini = 0.472 nsamples = 21 nvalue = [13, 8]&#39;), Text(0.20588235294117646, 0.6538461538461539, &#39;gini = 0.0 nsamples = 8 nvalue = [8, 0]&#39;), Text(0.40441176470588236, 0.8076923076923077, &#39;X[1] &lt;= 3.5 ngini = 0.242 nsamples = 363 nvalue = [312, 51]&#39;), Text(0.375, 0.7307692307692307, &#39;gini = 0.444 nsamples = 15 nvalue = [5, 10]&#39;), Text(0.4338235294117647, 0.7307692307692307, &#39;X[1] &lt;= 32.5 ngini = 0.208 nsamples = 348 nvalue = [307, 41]&#39;), Text(0.27941176470588236, 0.6538461538461539, &#39;X[1] &lt;= 30.75 ngini = 0.239 nsamples = 260 nvalue = [224, 36]&#39;), Text(0.25, 0.5769230769230769, &#39;X[1] &lt;= 10.0 ngini = 0.215 nsamples = 245 nvalue = [215, 30]&#39;), Text(0.22058823529411764, 0.5, &#39;gini = 0.444 nsamples = 9 nvalue = [6, 3]&#39;), Text(0.27941176470588236, 0.5, &#39;X[1] &lt;= 25.57 ngini = 0.203 nsamples = 236 nvalue = [209, 27]&#39;), Text(0.17647058823529413, 0.4230769230769231, &#39;X[0] &lt;= 2.5 ngini = 0.177 nsamples = 183 nvalue = [165, 18]&#39;), Text(0.14705882352941177, 0.34615384615384615, &#39;gini = 0.095 nsamples = 20 nvalue = [19, 1]&#39;), Text(0.20588235294117646, 0.34615384615384615, &#39;X[1] &lt;= 19.5 ngini = 0.187 nsamples = 163 nvalue = [146, 17]&#39;), Text(0.14705882352941177, 0.2692307692307692, &#39;X[1] &lt;= 18.5 ngini = 0.117 nsamples = 32 nvalue = [30, 2]&#39;), Text(0.11764705882352941, 0.19230769230769232, &#39;gini = 0.159 nsamples = 23 nvalue = [21, 2]&#39;), Text(0.17647058823529413, 0.19230769230769232, &#39;gini = 0.0 nsamples = 9 nvalue = [9, 0]&#39;), Text(0.2647058823529412, 0.2692307692307692, &#39;X[1] &lt;= 20.25 ngini = 0.203 nsamples = 131 nvalue = [116, 15]&#39;), Text(0.23529411764705882, 0.19230769230769232, &#39;gini = 0.298 nsamples = 11 nvalue = [9, 2]&#39;), Text(0.29411764705882354, 0.19230769230769232, &#39;X[1] &lt;= 23.75 ngini = 0.193 nsamples = 120 nvalue = [107, 13]&#39;), Text(0.2647058823529412, 0.11538461538461539, &#39;gini = 0.147 nsamples = 25 nvalue = [23, 2]&#39;), Text(0.3235294117647059, 0.11538461538461539, &#39;X[1] &lt;= 25.07 ngini = 0.205 nsamples = 95 nvalue = [84, 11]&#39;), Text(0.29411764705882354, 0.038461538461538464, &#39;gini = 0.255 nsamples = 20 nvalue = [17, 3]&#39;), Text(0.35294117647058826, 0.038461538461538464, &#39;gini = 0.191 nsamples = 75 nvalue = [67, 8]&#39;), Text(0.38235294117647056, 0.4230769230769231, &#39;X[1] &lt;= 29.939 ngini = 0.282 nsamples = 53 nvalue = [44, 9]&#39;), Text(0.35294117647058826, 0.34615384615384615, &#39;X[0] &lt;= 2.5 ngini = 0.331 nsamples = 43 nvalue = [34, 9]&#39;), Text(0.3235294117647059, 0.2692307692307692, &#39;gini = 0.198 nsamples = 18 nvalue = [16, 2]&#39;), Text(0.38235294117647056, 0.2692307692307692, &#39;gini = 0.403 nsamples = 25 nvalue = [18, 7]&#39;), Text(0.4117647058823529, 0.34615384615384615, &#39;gini = 0.0 nsamples = 10 nvalue = [10, 0]&#39;), Text(0.3088235294117647, 0.5769230769230769, &#39;gini = 0.48 nsamples = 15 nvalue = [9, 6]&#39;), Text(0.5882352941176471, 0.6538461538461539, &#39;X[1] &lt;= 61.5 ngini = 0.107 nsamples = 88 nvalue = [83, 5]&#39;), Text(0.5588235294117647, 0.5769230769230769, &#39;X[1] &lt;= 44.5 ngini = 0.093 nsamples = 82 nvalue = [78, 4]&#39;), Text(0.5294117647058824, 0.5, &#39;X[1] &lt;= 38.5 ngini = 0.126 nsamples = 59 nvalue = [55, 4]&#39;), Text(0.5, 0.4230769230769231, &#39;X[0] &lt;= 2.5 ngini = 0.059 nsamples = 33 nvalue = [32, 1]&#39;), Text(0.47058823529411764, 0.34615384615384615, &#39;gini = 0.153 nsamples = 12 nvalue = [11, 1]&#39;), Text(0.5294117647058824, 0.34615384615384615, &#39;gini = 0.0 nsamples = 21 nvalue = [21, 0]&#39;), Text(0.5588235294117647, 0.4230769230769231, &#39;gini = 0.204 nsamples = 26 nvalue = [23, 3]&#39;), Text(0.5882352941176471, 0.5, &#39;gini = 0.0 nsamples = 23 nvalue = [23, 0]&#39;), Text(0.6176470588235294, 0.5769230769230769, &#39;gini = 0.278 nsamples = 6 nvalue = [5, 1]&#39;), Text(0.7941176470588235, 0.8846153846153846, &#39;X[0] &lt;= 2.5 ngini = 0.394 nsamples = 248 nvalue = [67, 181]&#39;), Text(0.7058823529411765, 0.8076923076923077, &#39;X[1] &lt;= 2.5 ngini = 0.087 nsamples = 131 nvalue = [6, 125]&#39;), Text(0.6764705882352942, 0.7307692307692307, &#39;gini = 0.0 nsamples = 1 nvalue = [1, 0]&#39;), Text(0.7352941176470589, 0.7307692307692307, &#39;X[1] &lt;= 43.5 ngini = 0.074 nsamples = 130 nvalue = [5, 125]&#39;), Text(0.7058823529411765, 0.6538461538461539, &#39;X[1] &lt;= 26.5 ngini = 0.037 nsamples = 106 nvalue = [2, 104]&#39;), Text(0.6764705882352942, 0.5769230769230769, &#39;X[1] &lt;= 25.5 ngini = 0.083 nsamples = 46 nvalue = [2, 44]&#39;), Text(0.6470588235294118, 0.5, &#39;X[1] &lt;= 23.5 ngini = 0.043 nsamples = 45 nvalue = [1, 44]&#39;), Text(0.6176470588235294, 0.4230769230769231, &#39;gini = 0.0 nsamples = 32 nvalue = [0, 32]&#39;), Text(0.6764705882352942, 0.4230769230769231, &#39;gini = 0.142 nsamples = 13 nvalue = [1, 12]&#39;), Text(0.7058823529411765, 0.5, &#39;gini = 0.0 nsamples = 1 nvalue = [1, 0]&#39;), Text(0.7352941176470589, 0.5769230769230769, &#39;gini = 0.0 nsamples = 60 nvalue = [0, 60]&#39;), Text(0.7647058823529411, 0.6538461538461539, &#39;gini = 0.219 nsamples = 24 nvalue = [3, 21]&#39;), Text(0.8823529411764706, 0.8076923076923077, &#39;X[1] &lt;= 27.5 ngini = 0.499 nsamples = 117 nvalue = [61, 56]&#39;), Text(0.8529411764705882, 0.7307692307692307, &#39;X[1] &lt;= 1.5 ngini = 0.497 nsamples = 93 nvalue = [43, 50]&#39;), Text(0.8235294117647058, 0.6538461538461539, &#39;gini = 0.0 nsamples = 4 nvalue = [0, 4]&#39;), Text(0.8823529411764706, 0.6538461538461539, &#39;X[1] &lt;= 21.5 ngini = 0.499 nsamples = 89 nvalue = [43, 46]&#39;), Text(0.8235294117647058, 0.5769230769230769, &#39;X[1] &lt;= 5.5 ngini = 0.473 nsamples = 39 nvalue = [24, 15]&#39;), Text(0.7941176470588235, 0.5, &#39;gini = 0.48 nsamples = 10 nvalue = [4, 6]&#39;), Text(0.8529411764705882, 0.5, &#39;gini = 0.428 nsamples = 29 nvalue = [20, 9]&#39;), Text(0.9411764705882353, 0.5769230769230769, &#39;X[1] &lt;= 26.5 ngini = 0.471 nsamples = 50 nvalue = [19, 31]&#39;), Text(0.9117647058823529, 0.5, &#39;X[1] &lt;= 25.07 ngini = 0.475 nsamples = 49 nvalue = [19, 30]&#39;), Text(0.8823529411764706, 0.4230769230769231, &#39;gini = 0.496 nsamples = 11 nvalue = [5, 6]&#39;), Text(0.9411764705882353, 0.4230769230769231, &#39;X[1] &lt;= 25.57 ngini = 0.465 nsamples = 38 nvalue = [14, 24]&#39;), Text(0.9117647058823529, 0.34615384615384615, &#39;gini = 0.467 nsamples = 35 nvalue = [13, 22]&#39;), Text(0.9705882352941176, 0.34615384615384615, &#39;gini = 0.444 nsamples = 3 nvalue = [1, 2]&#39;), Text(0.9705882352941176, 0.5, &#39;gini = 0.0 nsamples = 1 nvalue = [0, 1]&#39;), Text(0.9117647058823529, 0.7307692307692307, &#39;gini = 0.375 nsamples = 24 nvalue = [18, 6]&#39;)] . findfont: Font family [&#39;NanumBarunGothic&#39;] not found. Falling back to DejaVu Sans. . model_30 = DecisionTreeClassifier(min_samples_split=30) model_30.fit(X_train, y_train) Y_pred = model_30.predict(X_test) model_30.score(X_train, y_train) submission = pd.DataFrame({ &quot;PassengerId&quot;: test[&quot;PassengerId&quot;], &quot;Survived&quot;: Y_pred }) submission.to_csv(&#39;titanic.csv&#39;, index=False) . import os print(os.getcwd()) . /content .",
            "url": "https://shw9807.github.io/shw9807blog/%EB%8D%B0%EC%9D%B4%EC%BD%98/2022/01/20/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html",
            "relUrl": "/%EB%8D%B0%EC%9D%B4%EC%BD%98/2022/01/20/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D.html",
            "date": " • Jan 20, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "[Colab] 영화 관객수 예측모델",
            "content": "&#50689;&#54868; &#44288;&#44061;&#49688; &#50696;&#52769; &#47784;&#45944; . EDA를 위한 패키지 불러오기 . !sudo apt-get install -y fonts-nanum !sudo fc-cache -fv !rm ~/.cache/matplotlib -rf . Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: fonts-nanum 0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded. Need to get 9,604 kB of archives. After this operation, 29.5 MB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB] Fetched 9,604 kB in 1s (8,421 kB/s) debconf: unable to initialize frontend: Dialog debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, &lt;&gt; line 1.) debconf: falling back to frontend: Readline debconf: unable to initialize frontend: Readline debconf: (This frontend requires a controlling tty.) debconf: falling back to frontend: Teletype dpkg-preconfigure: unable to re-open stdin: Selecting previously unselected package fonts-nanum. (Reading database ... 155229 files and directories currently installed.) Preparing to unpack .../fonts-nanum_20170925-1_all.deb ... Unpacking fonts-nanum (20170925-1) ... Setting up fonts-nanum (20170925-1) ... Processing triggers for fontconfig (2.12.6-0ubuntu2) ... /usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs /usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs /usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs /usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs /usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs /usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs /root/.local/share/fonts: skipping, no such directory /root/.fonts: skipping, no such directory /var/cache/fontconfig: cleaning cache directory /root/.cache/fontconfig: not cleaning non-existent cache directory /root/.fontconfig: not cleaning non-existent cache directory fc-cache: succeeded . import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import lightgbm as lgb import warnings warnings.filterwarnings(&quot;ignore&quot;) # 필요한 패키지와 라이브러리를 가져옴 import matplotlib as mpl import matplotlib.pyplot as plt import matplotlib.font_manager as fm %matplotlib inline plt.rc(&#39;font&#39;, family=&#39;NanumBarunGothic&#39;) mpl.rcParams[&#39;axes.unicode_minus&#39;] = False . import numpy as np . movies_test = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/영화관객수/movies_test.csv&quot;) movies_train = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/영화관객수/movies_train.csv&quot;) . submission = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/영화관객수/submission.csv&quot;) . movies_train.head() . title distributor genre release_time time screening_rat director dir_prev_bfnum dir_prev_num num_staff num_actor box_off_num . 0 개들의 전쟁 | 롯데엔터테인먼트 | 액션 | 2012-11-22 | 96 | 청소년 관람불가 | 조병옥 | NaN | 0 | 91 | 2 | 23398 | . 1 내부자들 | (주)쇼박스 | 느와르 | 2015-11-19 | 130 | 청소년 관람불가 | 우민호 | 1161602.50 | 2 | 387 | 3 | 7072501 | . 2 은밀하게 위대하게 | (주)쇼박스 | 액션 | 2013-06-05 | 123 | 15세 관람가 | 장철수 | 220775.25 | 4 | 343 | 4 | 6959083 | . 3 나는 공무원이다 | (주)NEW | 코미디 | 2012-07-12 | 101 | 전체 관람가 | 구자홍 | 23894.00 | 2 | 20 | 6 | 217866 | . 4 불량남녀 | 쇼박스(주)미디어플렉스 | 코미디 | 2010-11-04 | 108 | 15세 관람가 | 신근호 | 1.00 | 1 | 251 | 2 | 483387 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; title : 영화의 제목 distributor : 배급사 genre : 장르 release_time : 개봉일 time : 상영시간(분) screening_rat : 상영등급 director : 감독이름 dir_prev_bfnum : 해당 감독이 이 영화를 만들기 전 제작에 참여한 영화에서의 평균 관객수(단 관객수가 알려지지 않은 영화 제외) dir_prev_num : 해당 감독이 이 영화를 만들기 전 제작에 참여한 영화의 개수(단 관객수가 알려지지 않은 영화 제외) num_staff : 스텝수 num_actor : 주연배우수 box_off_num : 관객수 . movies_train.isnull().any() . title False distributor False genre False release_time False time False screening_rat False director False dir_prev_bfnum True dir_prev_num False num_staff False num_actor False box_off_num False dtype: bool . dir_prev_bfnum 항목에 결측치가 존재함을 알 수 있다. -&gt; 해당 영화가 그 감독의 첫 영화인 경우에 결측치를 가질 것이다. . movies_train[movies_train[&#39;dir_prev_bfnum&#39;].isnull() == True].head() . title distributor genre release_time time screening_rat director dir_prev_bfnum dir_prev_num num_staff num_actor box_off_num . 0 개들의 전쟁 | 롯데엔터테인먼트 | 액션 | 2012-11-22 | 96 | 청소년 관람불가 | 조병옥 | NaN | 0 | 91 | 2 | 23398 | . 6 길위에서 | 백두대간 | 다큐멘터리 | 2013-05-23 | 104 | 전체 관람가 | 이창재 | NaN | 0 | 32 | 5 | 53526 | . 8 1789, 바스티유의 연인들 | 유니버설픽쳐스인터내셔널코리아 | 뮤지컬 | 2014-09-18 | 129 | 전체 관람가 | 정성복 | NaN | 0 | 3 | 5 | 4778 | . 9 청춘그루브 | (주)두타연 | 드라마 | 2012-03-15 | 94 | 15세 관람가 | 변성현 | NaN | 0 | 138 | 3 | 868 | . 10 AV 아이돌 | (주) 케이알씨지 | 멜로/로맨스 | 2015-07-27 | 89 | 청소년 관람불가 | 조조 히데오 | NaN | 0 | 0 | 4 | 745 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; movies_train = movies_train.fillna(0) . movies_test = movies_test.fillna(0) . 결측치를 0으로 바꾸어 주었다. . movies_train.isnull().any() . title False distributor False genre False release_time False time False screening_rat False director False dir_prev_bfnum False dir_prev_num False num_staff False num_actor False box_off_num False dtype: bool . movies_test.isnull().any() . title False distributor False genre False release_time False time False screening_rat False director False dir_prev_bfnum False dir_prev_num False num_staff False num_actor False dtype: bool . 결측치가 없어진 것을 확인할 수 있다. . movies_train[&#39;month&#39;] = movies_train[&#39;release_time&#39;].str[5:7].astype(&#39;int&#39;) . plt.figure(figsize=[10,10]) sns.scatterplot(data=movies_train, x=&#39;month&#39;, y = &#39;box_off_num&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd8789c0510&gt; . 방학시즌에 개봉한 영화가 대체로 관객 수가 많은 것처럼 보인다. . plt.figure(figsize=[10,10]) sns.scatterplot(data=movies_train, x=&#39;num_staff&#39;, y = &#39;box_off_num&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd87898e490&gt; . 스태프 수가 많은 영화가 대체로 관객 수가 많은 것처럼 보인다. . plt.figure(figsize=[10,10]) sns.scatterplot(data=movies_train, x=&#39;screening_rat&#39;, y = &#39;box_off_num&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd8789735d0&gt; . 전체 관람가나 청소년 관람불가 영화보다는 12세관람가나 15세관람가 영화가 관객수가 많은 편인 것을 알 수 있다. . plt.figure(figsize=[10,10]) sns.scatterplot(data=movies_train, x=&#39;time&#39;, y = &#39;box_off_num&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd878917710&gt; . 상영시간이 지나치게 짧거나 2시간30분을 넘어가면 관객수가 대체로 적다는 것을 확인할 수 있다. . movies_train[[&#39;genre&#39;, &#39;box_off_num&#39;]].groupby(&#39;genre&#39;).mean().sort_values(&#39;box_off_num&#39;) . box_off_num . genre . 뮤지컬 6.627000e+03 | . 다큐멘터리 6.717226e+04 | . 서스펜스 8.261100e+04 | . 애니메이션 1.819267e+05 | . 멜로/로맨스 4.259680e+05 | . 미스터리 5.275482e+05 | . 공포 5.908325e+05 | . 드라마 6.256898e+05 | . 코미디 1.193914e+06 | . SF 1.788346e+06 | . 액션 2.203974e+06 | . 느와르 2.263695e+06 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; 장르별로 평균 관객수를 정렬해보았다. 액션과 느와르 장르가 대체적으로 관객수가 많은 것을 확인할 수 있다. . %matplotlib inline movies_train.hist(bins = 50, figsize = (20,15)) plt.show() . 변수별로 히스토그램을 그려보았다. . sns.heatmap(movies_train.corr(), annot = True) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd86f758e50&gt; . 히트맵그림을 그려보았다.관객수와 상관관계가 있어보이는 변수는 스태프의 수와 상영시간 정도로 보인다. . &#48320;&#49688; &#49440;&#53469;&#44284; &#47784;&#45944; &#44396;&#52629; . lightGBM (base model) . model = lgb.LGBMRegressor(n_estimators=1000) . features = [&#39;time&#39;, &#39;dir_prev_num&#39;, &#39;num_staff&#39;, &#39;num_actor&#39;] target = [&#39;box_off_num&#39;] . X_train, X_test, y_train = movies_train[features], movies_test[features], movies_train[target] . model.fit(X_train, y_train) . LGBMRegressor(n_estimators=1000) . singleLGBM = submission.copy() . singleLGBM[&#39;box_off_num&#39;] = model.predict(X_test) . singleLGBM.head() . title box_off_num . 0 용서는 없다 | 2.817995e+06 | . 1 아빠가 여자를 좋아해 | 3.753772e+05 | . 2 하모니 | -5.693243e+05 | . 3 의형제 | 1.581189e+06 | . 4 평행 이론 | -5.277806e+05 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; 음수가 나오므로 잘못된 것 같다. . RMSE 점수를 확인하기 위해서 train 데이터로 학습시킨 모델을 다시 train 데이터에 적용하여 관객수를 구하고 RMSE를 구해보자. 그리고 변수는 어느정도 상관계수가 커보였던 상영시간과 스태프 수 만을 사용하기로 하자. . features = [&#39;time&#39;, &#39;num_staff&#39;] target = [&#39;box_off_num&#39;] . X_train, X_test, y_train = movies_train[features], movies_train[features], movies_train[target] . model.fit(X_train, y_train) . LGBMRegressor(n_estimators=1000) . singleLGBM = movies_train.copy() . singleLGBM[&#39;box_off_num&#39;] = model.predict(X_test) . singleLGBM.head() . title distributor genre release_time time screening_rat director dir_prev_bfnum dir_prev_num num_staff num_actor box_off_num month . 0 개들의 전쟁 | 롯데엔터테인먼트 | 액션 | 2012-11-22 | 96 | 청소년 관람불가 | 조병옥 | 0.00 | 0 | 91 | 2 | 4.245526e+03 | 11 | . 1 내부자들 | (주)쇼박스 | 느와르 | 2015-11-19 | 130 | 청소년 관람불가 | 우민호 | 1161602.50 | 2 | 387 | 3 | 6.805784e+06 | 11 | . 2 은밀하게 위대하게 | (주)쇼박스 | 액션 | 2013-06-05 | 123 | 15세 관람가 | 장철수 | 220775.25 | 4 | 343 | 4 | 6.577795e+06 | 6 | . 3 나는 공무원이다 | (주)NEW | 코미디 | 2012-07-12 | 101 | 전체 관람가 | 구자홍 | 23894.00 | 2 | 20 | 6 | 4.453083e+04 | 7 | . 4 불량남녀 | 쇼박스(주)미디어플렉스 | 코미디 | 2010-11-04 | 108 | 15세 관람가 | 신근호 | 1.00 | 1 | 251 | 2 | 8.484480e+05 | 11 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; def RMSE(true, pred): score = np.sqrt(np.mean(np.square(true-pred))) return score . RMSE(movies_train[&#39;box_off_num&#39;],singleLGBM[&#39;box_off_num&#39;]) . 776662.1566623428 . RMSE가 776,662 정도 나오는 것을 확인할 수 있다. 다른 모델도 사용해서 RMSE를 더 줄일 수 있는지 확인해보자. . from sklearn.model_selection import KFold . k_fold = KFold(n_splits=5, shuffle=True) . model = lgb.LGBMRegressor(n_estimators=1000) models = [] # 모델을 담을 바구니라 생각하자. for train_idx, val_idx in k_fold.split(X_train): x_t = X_train.iloc[train_idx] y_t = y_train.iloc[train_idx] x_val = X_train.iloc[val_idx] y_val = y_train.iloc[val_idx] models.append(model.fit(x_t, y_t, eval_set=(x_val, y_val), early_stopping_rounds=100, verbose = 100)) . Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 1.85132e+12 Early stopping, best iteration is: [7] valid_0&#39;s l2: 1.4462e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 3.34081e+12 Early stopping, best iteration is: [14] valid_0&#39;s l2: 2.88132e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 1.97832e+12 Early stopping, best iteration is: [23] valid_0&#39;s l2: 1.8693e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 1.72764e+12 Early stopping, best iteration is: [29] valid_0&#39;s l2: 1.60885e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 3.40884e+12 Early stopping, best iteration is: [26] valid_0&#39;s l2: 3.16161e+12 . models . [LGBMRegressor(n_estimators=1000), LGBMRegressor(n_estimators=1000), LGBMRegressor(n_estimators=1000), LGBMRegressor(n_estimators=1000), LGBMRegressor(n_estimators=1000)] . preds = [] for model in models: preds.append(model.predict(X_train)) len(preds) . 5 . pred에 만들어둔 모델들의 예측값들을 저장해준다. . kfoldLightGBM = movies_train.copy() # 답안지 복사. . kfoldLightGBM[&#39;box_off_num&#39;] = np.mean(preds, axis = 0) # mean 평균값함수,axis 축 . RMSE(movies_train[&#39;box_off_num&#39;],kfoldLightGBM[&#39;box_off_num&#39;]) . 1375351.354121486 . RMSE가 1,375,351로 매우 커졌다. 왜일까....?? . from sklearn import preprocessing le = preprocessing.LabelEncoder() movies_train[&#39;genre&#39;] = le.fit_transform(movies_train[&#39;genre&#39;]) . sklearn에서 제공하는 labelEncoder를 활용해서 문자열을 숫자로 변환했다. . features = [&#39;time&#39;, &#39;num_staff&#39;, &#39;dir_prev_bfnum&#39;, &#39;genre&#39;] . features에 전처리된 dir_prev_bfnum와 문자열을 숫자로 변환한 genre를 추가했다. . X_train, X_test, y_train = movies_train[features], movies_train[features], movies_train[target] . model = lgb.LGBMRegressor(random_state=777, n_estimators=1000) models = [] for train_idx, val_idx in k_fold.split(X_train): x_t = X_train.iloc[train_idx] y_t = y_train.iloc[train_idx] x_val = X_train.iloc[val_idx] y_val = y_train.iloc[val_idx] models.append(model.fit(x_t, y_t, eval_set=(x_val, y_val), early_stopping_rounds=100, verbose = 100)) . Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 2.0569e+12 Early stopping, best iteration is: [15] valid_0&#39;s l2: 1.87889e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 1.78541e+12 Early stopping, best iteration is: [9] valid_0&#39;s l2: 1.29506e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 2.30124e+12 Early stopping, best iteration is: [33] valid_0&#39;s l2: 2.12538e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 4.67408e+12 Early stopping, best iteration is: [22] valid_0&#39;s l2: 4.06655e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 2.30679e+12 Early stopping, best iteration is: [17] valid_0&#39;s l2: 1.76818e+12 . preds = [] for model in models: preds.append(model.predict(X_test)) len(preds) . 5 . feLightGBM = movies_train.copy() . feLightGBM[&#39;box_off_num&#39;] = np.mean(preds, axis = 0) . RMSE(movies_train[&#39;box_off_num&#39;],feLightGBM[&#39;box_off_num&#39;]) . 1360591.313400032 . 바로 위의 RMSE보다는 어느 정도 작아진 것을 알 수 있다. . Grid search &#47784;&#45944; . from sklearn.model_selection import GridSearchCV . model = lgb.LGBMRegressor(n_estimators=1000) . params = { &#39;learning_rate&#39;: [0.1, 0.01, 0.003], &#39;min_child_samples&#39;: [20, 30]} gs = GridSearchCV(estimator=model, param_grid=params, scoring= &#39;neg_mean_squared_error&#39;, cv = k_fold) . params에서 learning_rate는 모델링을 하는 간격으로, 값이 적을수록 점점 더 미세하게 모델의 변화가 이루어진다로 생각하면 된다. scoring을 rmse로 한 이후는 현재 이 대회의 평가지표가 rmse값이기 때문 . gs.fit(X_train, y_train) . GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True), estimator=LGBMRegressor(n_estimators=1000), param_grid={&#39;learning_rate&#39;: [0.1, 0.01, 0.003], &#39;min_child_samples&#39;: [20, 30]}, scoring=&#39;neg_mean_squared_error&#39;) . gs.best_params_ . {&#39;learning_rate&#39;: 0.003, &#39;min_child_samples&#39;: 30} . model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.003, min_child_samples=30) models = [] for train_idx, val_idx in k_fold.split(X_train): x_t = X_train.iloc[train_idx] y_t = y_train.iloc[train_idx] x_val = X_train.iloc[val_idx] y_val = y_train.iloc[val_idx] models.append(model.fit(x_t, y_t, eval_set=(x_val, y_val), early_stopping_rounds=100, verbose = 100)) . Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 4.88516e+12 [200] valid_0&#39;s l2: 4.42603e+12 [300] valid_0&#39;s l2: 4.13354e+12 [400] valid_0&#39;s l2: 3.97867e+12 [500] valid_0&#39;s l2: 3.87486e+12 [600] valid_0&#39;s l2: 3.80364e+12 [700] valid_0&#39;s l2: 3.75367e+12 [800] valid_0&#39;s l2: 3.73486e+12 [900] valid_0&#39;s l2: 3.73187e+12 Early stopping, best iteration is: [889] valid_0&#39;s l2: 3.73167e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 2.18551e+12 [200] valid_0&#39;s l2: 1.88159e+12 [300] valid_0&#39;s l2: 1.71548e+12 [400] valid_0&#39;s l2: 1.6308e+12 [500] valid_0&#39;s l2: 1.60349e+12 [600] valid_0&#39;s l2: 1.59885e+12 [700] valid_0&#39;s l2: 1.59966e+12 Early stopping, best iteration is: [628] valid_0&#39;s l2: 1.59791e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 1.63836e+12 [200] valid_0&#39;s l2: 1.49624e+12 [300] valid_0&#39;s l2: 1.37358e+12 [400] valid_0&#39;s l2: 1.28814e+12 [500] valid_0&#39;s l2: 1.23785e+12 [600] valid_0&#39;s l2: 1.2091e+12 [700] valid_0&#39;s l2: 1.18886e+12 [800] valid_0&#39;s l2: 1.17838e+12 [900] valid_0&#39;s l2: 1.15994e+12 [1000] valid_0&#39;s l2: 1.14697e+12 Did not meet early stopping. Best iteration is: [1000] valid_0&#39;s l2: 1.14697e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 1.54254e+12 [200] valid_0&#39;s l2: 1.32956e+12 [300] valid_0&#39;s l2: 1.26545e+12 [400] valid_0&#39;s l2: 1.26595e+12 Early stopping, best iteration is: [335] valid_0&#39;s l2: 1.2583e+12 Training until validation scores don&#39;t improve for 100 rounds. [100] valid_0&#39;s l2: 3.88743e+12 [200] valid_0&#39;s l2: 3.52199e+12 [300] valid_0&#39;s l2: 3.32668e+12 [400] valid_0&#39;s l2: 3.26764e+12 [500] valid_0&#39;s l2: 3.22996e+12 [600] valid_0&#39;s l2: 3.2196e+12 [700] valid_0&#39;s l2: 3.21357e+12 [800] valid_0&#39;s l2: 3.21046e+12 [900] valid_0&#39;s l2: 3.20925e+12 [1000] valid_0&#39;s l2: 3.2054e+12 Did not meet early stopping. Best iteration is: [999] valid_0&#39;s l2: 3.20518e+12 . preds = [] for model in models: preds.append(model.predict(X_test)) . gslgbm = movies_train.copy() . gslgbm[&#39;box_off_num&#39;] = np.mean(preds, axis=0) . RMSE(movies_train[&#39;box_off_num&#39;],gslgbm[&#39;box_off_num&#39;]) . 1371034.705755213 . 위보다는 조금 더 작아졌는데 왜이렇게 클까....?? . train 데이터를 train 과 test로 나눠서 확인을 했어야 하는데 train 데이터 전체로 모델을 만든 뒤 train데이터 전체를 사용해서 예측을 해서 이상해진 것 같다....?? . train 데이터로 모델을 만들고 정확히 같은 데이터를 예측하게 했는데 RMSE가 왜 저렇게 크게 나오는 걸까 .",
            "url": "https://shw9807.github.io/shw9807blog/%EB%8D%B0%EC%9D%B4%EC%BD%98/2022/01/13/%EC%98%81%ED%99%94%EA%B4%80%EA%B0%9D%EC%88%98_%EC%98%88%EC%B8%A1_%EB%AA%A8%EB%8D%B8.html",
            "relUrl": "/%EB%8D%B0%EC%9D%B4%EC%BD%98/2022/01/13/%EC%98%81%ED%99%94%EA%B4%80%EA%B0%9D%EC%88%98_%EC%98%88%EC%B8%A1_%EB%AA%A8%EB%8D%B8.html",
            "date": " • Jan 13, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "about",
          "content": "2022년부터 ML/DL 공부중 .",
          "url": "https://shw9807.github.io/shw9807blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://shw9807.github.io/shw9807blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}